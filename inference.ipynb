{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b82eb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import argparse\n",
    "import json\n",
    "import torch\n",
    "from scipy.io.wavfile import write\n",
    "from env import AttrDict\n",
    "from meldataset import mel_spectrogram, MAX_WAV_VALUE, load_wav\n",
    "from models import Generator\n",
    "from stft import TorchSTFT\n",
    "\n",
    "from Utils.JDC.model import JDCNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee13ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = None\n",
    "device = None\n",
    "\n",
    "\n",
    "def load_checkpoint(filepath, device):\n",
    "    assert os.path.isfile(filepath)\n",
    "    print(\"Loading '{}'\".format(filepath))\n",
    "    checkpoint_dict = torch.load(filepath, map_location=device)\n",
    "    print(\"Complete.\")\n",
    "    return checkpoint_dict\n",
    "\n",
    "\n",
    "def get_mel(x):\n",
    "    return mel_spectrogram(x, h.n_fft, h.num_mels, h.sampling_rate, h.hop_size, h.win_size, h.fmin, h.fmax)\n",
    "\n",
    "\n",
    "def scan_checkpoint(cp_dir, prefix):\n",
    "    pattern = os.path.join(cp_dir, prefix + '*')\n",
    "    cp_list = glob.glob(pattern)\n",
    "    if len(cp_list) == 0:\n",
    "        return ''\n",
    "    return sorted(cp_list)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003b1249",
   "metadata": {},
   "outputs": [],
   "source": [
    "F0_model = JDCNet(num_class=1, seq_len=192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321eb3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_path = \"cp_hifigan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcc2764",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cp_path + \"/config.json\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "json_config = json.loads(data)\n",
    "h = AttrDict(json_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c78cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:{:d}'.format(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a782adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(h, F0_model).to(device)\n",
    "stft = TorchSTFT(filter_length=h.gen_istft_n_fft, hop_length=h.gen_istft_hop_size, win_length=h.gen_istft_n_fft).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0a7c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_g = scan_checkpoint(cp_path, 'g_')\n",
    "state_dict_g = load_checkpoint(cp_g, device)\n",
    "generator.load_state_dict(state_dict_g['generator'])\n",
    "generator.remove_weight_norm()\n",
    "_ = generator.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a115a967",
   "metadata": {},
   "source": [
    "### Resynthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a0743f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a file to resynthesize\n",
    "path = os.path.join(\"LJSpeech-1.1/wavs\", \"LJ049-0163.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc57291a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav, sr = load_wav(path)\n",
    "wav = wav / MAX_WAV_VALUE\n",
    "wav = torch.FloatTensor(wav).to(device)\n",
    "x = get_mel(wav.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939f401e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    spec, phase = generator(x)\n",
    "    y_g_hat = stft.inverse(spec, phase)\n",
    "    audio = y_g_hat.squeeze()\n",
    "    audio = audio * MAX_WAV_VALUE\n",
    "    audio = audio.cpu().numpy().astype('int16')\n",
    "import IPython.display as ipd\n",
    "\n",
    "print('Synthesized:')\n",
    "display(ipd.Audio(audio, rate=22050))\n",
    "\n",
    "print('Original:')\n",
    "display(ipd.Audio(wav.cpu(), rate=22050))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
